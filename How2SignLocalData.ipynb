{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QUOmyMZKexU",
    "outputId": "61ca82f4-a5e9-413f-8f52-389439a5d4d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yugos\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "MediaPipe version: 0.10.21\n",
      "OpenCV version: 4.11.0\n",
      "Tensorflow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import tensorflow\n",
    "print(\"MediaPipe version:\", mp.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"Tensorflow version:\", tensorflow.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Preprocessing and Aligning Raw Data ---\n",
      "Aligning and processing 'training'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos: 100%|█████████████████████████████████████████████████| 182/182 [01:12<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed CSV for training with 182 aligned rows.\n",
      "Aligning and processing 'testing'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos: 100%|████████████████████████████████████████████████████| 84/84 [00:43<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed CSV for testing with 84 aligned rows.\n",
      "Aligning and processing 'validation'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos: 100%|█████████████████████████████████████████████████| 84/84 [00:33<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed CSV for validation with 84 aligned rows.\n",
      "\n",
      "All preprocessing and alignment complete.\n",
      "Total videos found after preprocessing: 350\n",
      "\n",
      "--- Phase 2: Fitting Normalizer on training data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Raw Training Keypoints: 100%|███████████████████████████████████████████| 182/182 [1:50:55<00:00, 36.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizer (MinMaxScaler) fitted on 34215 training frames.\n",
      "\n",
      "--- Phase 3: Normalizing, Padding, and Saving Sequences ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Processing and Saving: 100%|█████████████████████████████████████████████████| 350/350 [3:30:23<00:00, 36.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved training data: X_shape=(182, 60, 2172), y_shape=(182,)\n",
      "\n",
      "Saved testing data: X_shape=(84, 60, 2172), y_shape=(84,)\n",
      "\n",
      "Saved validation data: X_shape=(84, 60, 2172), y_shape=(84,)\n",
      "\n",
      "Label map saved with 305 unique sentences.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import ffmpeg\n",
    "from tqdm import tqdm # For visualizing progress\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Define the root directory for your raw data\n",
    "data_root_dir = \"data\"\n",
    "\n",
    "# Define the desired standard video format\n",
    "standard_fps = 30\n",
    "standard_resolution = \"640:480\" # Width:Height\n",
    "\n",
    "# List of folders and their corresponding CSV file names\n",
    "csv_files_info = {\n",
    "    \"training\": \"how2sign_realigned_train.csv\",\n",
    "    \"testing\": \"how2sign_realigned_test.csv\",\n",
    "    \"validation\": \"how2sign_realigned_val.csv\"\n",
    "}\n",
    "\n",
    "# The subfolder containing the raw videos\n",
    "raw_videos_subfolder = \"raw_videos\"\n",
    "\n",
    "# Output directory for the final processed NumPy arrays and CSVs\n",
    "OUTPUT_DATA_DIR = 'processed_gru_data'\n",
    "os.makedirs(OUTPUT_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Define Hyperparameters for the GRU Model Input\n",
    "SEQUENCE_LENGTH = 60\n",
    "\n",
    "# Initialize MediaPipe Holistic for extracting all landmarks (hands, face, pose)\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# --- 2. HELPER FUNCTIONS ---\n",
    "\n",
    "def extract_landmarks(results):\n",
    "    \"\"\"\n",
    "    Extracts and flattens all available MediaPipe landmarks into a single 1D array.\n",
    "    \"\"\"\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() \\\n",
    "        if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z, res.visibility] for res in results.face_landmarks.landmark]).flatten() \\\n",
    "        if results.face_landmarks else np.zeros(468*4)\n",
    "    lh = np.array([[res.x, res.y, res.z, res.visibility] for res in results.left_hand_landmarks.landmark]).flatten() \\\n",
    "        if results.left_hand_landmarks else np.zeros(21*4)\n",
    "    rh = np.array([[res.x, res.y, res.z, res.visibility] for res in results.right_hand_landmarks.landmark]).flatten() \\\n",
    "        if results.right_hand_landmarks else np.zeros(21*4)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "def process_and_extract_sequence(video_path, holistic_model):\n",
    "    \"\"\"\n",
    "    Reads a video and extracts the sequence of landmark features.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return None\n",
    "    frame_sequence = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic_model.process(image_rgb)\n",
    "        keypoints = extract_landmarks(results)\n",
    "        frame_sequence.append(keypoints)\n",
    "    cap.release()\n",
    "    return np.array(frame_sequence)\n",
    "\n",
    "def normalize_and_pad_sequence(sequence, scaler, max_length=SEQUENCE_LENGTH):\n",
    "    \"\"\"Normalizes coordinates and pads/truncates the sequence to a fixed length.\"\"\"\n",
    "    if sequence.size == 0:\n",
    "        return np.zeros((max_length, scaler.n_features_in_))\n",
    "    normalized_sequence = scaler.transform(sequence)\n",
    "    if normalized_sequence.shape[0] < max_length:\n",
    "        padding_needed = max_length - normalized_sequence.shape[0]\n",
    "        padding = np.zeros((padding_needed, normalized_sequence.shape[1]))\n",
    "        padded_sequence = np.concatenate([normalized_sequence, padding], axis=0)\n",
    "    elif normalized_sequence.shape[0] > max_length:\n",
    "        padded_sequence = normalized_sequence[:max_length, :]\n",
    "    else:\n",
    "        padded_sequence = normalized_sequence\n",
    "    return padded_sequence\n",
    "    \n",
    "# --- 3. MAIN EXECUTION ---\n",
    "def main():\n",
    "    \n",
    "    # --- Phase 1: Preprocessing and Aligning Raw Data ---\n",
    "    print(\"--- Phase 1: Preprocessing and Aligning Raw Data ---\")\n",
    "    \n",
    "    all_video_data_from_processed_dirs = []\n",
    "    \n",
    "    for folder_name, csv_file_name in csv_files_info.items():\n",
    "        input_videos_dir = os.path.join(data_root_dir, folder_name, raw_videos_subfolder)\n",
    "        input_csv_path = os.path.join(data_root_dir, folder_name, csv_file_name)\n",
    "        \n",
    "        processed_videos_dir = os.path.join(data_root_dir, f\"processed_{folder_name}\", \"videos\")\n",
    "        processed_csv_dir = os.path.join(data_root_dir, f\"processed_{folder_name}\")\n",
    "        os.makedirs(processed_videos_dir, exist_ok=True)\n",
    "        os.makedirs(processed_csv_dir, exist_ok=True)\n",
    "\n",
    "        print(f\"Aligning and processing '{folder_name}'...\")\n",
    "        \n",
    "        if not os.path.exists(input_videos_dir) or not os.path.exists(input_csv_path):\n",
    "            print(f\"Warning: Raw data not found for '{folder_name}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        df_raw = pd.read_csv(input_csv_path, sep='\\t')\n",
    "        \n",
    "        processed_rows = []\n",
    "        video_id_counter = 0\n",
    "\n",
    "        raw_video_files = [f for f in os.listdir(input_videos_dir) if f.endswith((\".mp4\", \".mov\", \".avi\", \".mkv\"))]\n",
    "        raw_video_names_without_ext = {os.path.splitext(f)[0] for f in raw_video_files}\n",
    "        \n",
    "        df_aligned = df_raw[df_raw['SENTENCE_NAME'].isin(raw_video_names_without_ext)].copy()\n",
    "\n",
    "        for index, row in tqdm(df_aligned.iterrows(), total=len(df_aligned), desc=f\"Standardizing {folder_name} videos\"):\n",
    "            video_name = row['SENTENCE_NAME']\n",
    "            label = row['SENTENCE']\n",
    "            \n",
    "            video_file_with_ext = next((f for f in raw_video_files if os.path.splitext(f)[0] == video_name), None)\n",
    "            if video_file_with_ext is None:\n",
    "                continue\n",
    "                \n",
    "            input_video_path = os.path.join(input_videos_dir, video_file_with_ext)\n",
    "            output_video_path = os.path.join(processed_videos_dir, f\"standardized_{video_name}.mp4\")\n",
    "\n",
    "            try:\n",
    "                (\n",
    "                    ffmpeg\n",
    "                    .input(input_video_path)\n",
    "                    .output(output_video_path, vf=f\"fps={standard_fps},scale={standard_resolution}\", vcodec=\"libx264\", crf=20)\n",
    "                    .run(overwrite_output=True, quiet=True)\n",
    "                )\n",
    "                \n",
    "                processed_row = {\n",
    "                    'video_id': video_id_counter,\n",
    "                    'SENTENCE_NAME': f\"standardized_{video_name}\",\n",
    "                    'SENTENCE': label\n",
    "                }\n",
    "                processed_rows.append(processed_row)\n",
    "                video_id_counter += 1\n",
    "\n",
    "            except ffmpeg.Error:\n",
    "                print(f\"Warning: FFmpeg standardization failed for {video_name}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "        processed_df = pd.DataFrame(processed_rows)\n",
    "        processed_df.to_csv(os.path.join(processed_csv_dir, f\"processed_{folder_name}.csv\"), sep='\\t', index=False)\n",
    "        print(f\"Saved processed CSV for {folder_name} with {len(processed_rows)} aligned rows.\")\n",
    "        \n",
    "        for row in processed_rows:\n",
    "            video_path = os.path.join(processed_videos_dir, row['SENTENCE_NAME'] + '.mp4')\n",
    "            all_video_data_from_processed_dirs.append((video_path, row['SENTENCE'], folder_name))\n",
    "\n",
    "    print(\"\\nAll preprocessing and alignment complete.\")\n",
    "    print(f\"Total videos found after preprocessing: {len(all_video_data_from_processed_dirs)}\")\n",
    "    \n",
    "    # --- Phase 2: First Pass - Extract & fit scaler on training data ---\n",
    "    print(\"\\n--- Phase 2: Fitting Normalizer on training data ---\")\n",
    "    training_data_raw = []\n",
    "    training_data = [item for item in all_video_data_from_processed_dirs if item[2] == 'training']\n",
    "\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for video_path, _, _ in tqdm(training_data, desc=\"Extracting Raw Training Keypoints\"):\n",
    "            raw_sequence = process_and_extract_sequence(video_path, holistic)\n",
    "            if raw_sequence is not None and raw_sequence.size > 0:\n",
    "                training_data_raw.append(raw_sequence)\n",
    "\n",
    "    if not training_data_raw:\n",
    "        print(\"No training data found. Cannot fit scaler. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    combined_train_frames = np.vstack(training_data_raw)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(combined_train_frames)\n",
    "    print(f\"Normalizer (MinMaxScaler) fitted on {combined_train_frames.shape[0]} training frames.\")\n",
    "\n",
    "    # --- Phase 3: Second Pass - Process, Normalize, and Save ---\n",
    "    print(\"\\n--- Phase 3: Normalizing, Padding, and Saving Sequences ---\")\n",
    "    final_data = {'training': {'X': [], 'y': []}, \n",
    "                  'testing': {'X': [], 'y': []}, \n",
    "                  'validation': {'X': [], 'y': []}}\n",
    "    unique_labels = sorted(list(set(item[1] for item in all_video_data_from_processed_dirs)))\n",
    "    label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for video_path, label, folder_type in tqdm(all_video_data_from_processed_dirs, desc=\"Final Processing and Saving\"):\n",
    "            raw_sequence = process_and_extract_sequence(video_path, holistic)\n",
    "            if raw_sequence is None or raw_sequence.size == 0:\n",
    "                continue\n",
    "            padded_sequence = normalize_and_pad_sequence(raw_sequence, scaler)\n",
    "            int_label = label_to_int[label]\n",
    "            final_data[folder_type]['X'].append(padded_sequence)\n",
    "            final_data[folder_type]['y'].append(int_label)\n",
    "    \n",
    "    for set_key, data in final_data.items():\n",
    "        if data['X']:\n",
    "            X_data = np.array(data['X'])\n",
    "            y_data = np.array(data['y'])\n",
    "            np.save(os.path.join(OUTPUT_DATA_DIR, f'X_{set_key}.npy'), X_data)\n",
    "            np.save(os.path.join(OUTPUT_DATA_DIR, f'y_{set_key}.npy'), y_data)\n",
    "            print(f\"\\nSaved {set_key} data: X_shape={X_data.shape}, y_shape={y_data.shape}\")\n",
    "\n",
    "    label_df = pd.DataFrame(list(label_to_int.items()), columns=['SENTENCE', 'LABEL_INT'])\n",
    "    label_df.to_csv(os.path.join(OUTPUT_DATA_DIR, 'label_map.csv'), index=False)\n",
    "    print(f\"\\nLabel map saved with {len(unique_labels)} unique sentences.\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Loading Processed Data ---\n",
      "Total videos found across all sets: 350\n",
      "\n",
      "--- Phase 2: Fitting Normalizer on training data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Raw Training Keypoints: 100%|███████████████████████████████████████████| 182/182 [1:43:26<00:00, 34.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizer (MinMaxScaler) fitted on 34215 training frames.\n",
      "\n",
      "--- Phase 3: Normalizing, Padding, and Saving Sequences ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Processing and Saving: 100%|█████████████████████████████████████████████████| 350/350 [3:31:11<00:00, 36.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved training data: X_shape=(182, 60, 2172), y_shape=(182,)\n",
      "\n",
      "Saved testing data: X_shape=(84, 60, 2172), y_shape=(84,)\n",
      "\n",
      "Saved validation data: X_shape=(84, 60, 2172), y_shape=(84,)\n",
      "\n",
      "Label map saved with 305 unique sentences.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm # For visualizing progress\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Define the root directory where your processed data resides.\n",
    "ROOT_DIR = 'data'\n",
    "PROCESSED_FOLDERS = ['processed_training', 'processed_testing', 'processed_validation']\n",
    "# Output directory for the final processed NumPy arrays\n",
    "OUTPUT_DATA_DIR = 'processed_gru_data'\n",
    "os.makedirs(OUTPUT_DATA_DIR, exist_ok=True)\n",
    "# Define Hyperparameters for the GRU Model Input\n",
    "SEQUENCE_LENGTH = 60\n",
    "\n",
    "# Initialize MediaPipe Holistic for extracting all landmarks (hands, face, pose)\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# --- 2. HELPER FUNCTIONS ---\n",
    "def extract_landmarks(results):\n",
    "    \"\"\"\n",
    "    Extracts and flattens all available MediaPipe landmarks into a single 1D array.\n",
    "    \"\"\"\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() \\\n",
    "        if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z, res.visibility] for res in results.face_landmarks.landmark]).flatten() \\\n",
    "        if results.face_landmarks else np.zeros(468*4)\n",
    "    lh = np.array([[res.x, res.y, res.z, res.visibility] for res in results.left_hand_landmarks.landmark]).flatten() \\\n",
    "        if results.left_hand_landmarks else np.zeros(21*4)\n",
    "    rh = np.array([[res.x, res.y, res.z, res.visibility] for res in results.right_hand_landmarks.landmark]).flatten() \\\n",
    "        if results.right_hand_landmarks else np.zeros(21*4)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "def process_and_extract_sequence(video_path, holistic_model):\n",
    "    \"\"\"Reads a video and extracts the sequence of landmark features.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return None\n",
    "    frame_sequence = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic_model.process(image_rgb)\n",
    "        keypoints = extract_landmarks(results)\n",
    "        frame_sequence.append(keypoints)\n",
    "    cap.release()\n",
    "    return np.array(frame_sequence)\n",
    "\n",
    "def normalize_and_pad_sequence(sequence, scaler, max_length=SEQUENCE_LENGTH):\n",
    "    \"\"\"Normalizes coordinates and pads/truncates the sequence to a fixed length.\"\"\"\n",
    "    if sequence.size == 0:\n",
    "        return np.zeros((max_length, scaler.n_features_in_))\n",
    "    normalized_sequence = scaler.transform(sequence)\n",
    "    if normalized_sequence.shape[0] < max_length:\n",
    "        padding_needed = max_length - normalized_sequence.shape[0]\n",
    "        padding = np.zeros((padding_needed, normalized_sequence.shape[1]))\n",
    "        padded_sequence = np.concatenate([normalized_sequence, padding], axis=0)\n",
    "    elif normalized_sequence.shape[0] > max_length:\n",
    "        padded_sequence = normalized_sequence[:max_length, :]\n",
    "    else:\n",
    "        padded_sequence = normalized_sequence\n",
    "    return padded_sequence\n",
    "    \n",
    "# --- 3. MAIN EXECUTION ---\n",
    "def main():\n",
    "    all_video_data = []\n",
    "    \n",
    "    # --- Phase 1: Load data from already processed folders ---\n",
    "    print(\"--- Phase 1: Loading Processed Data ---\")\n",
    "    for folder in PROCESSED_FOLDERS:\n",
    "        # Correctly join the path for the processed CSV\n",
    "        # The filename created by the first script is 'processed_training.csv', etc.\n",
    "        label_csv_path = os.path.join(ROOT_DIR, folder, f\"{folder}.csv\") \n",
    "        videos_dir = os.path.join(ROOT_DIR, folder, \"videos\")\n",
    "        \n",
    "        if not os.path.exists(label_csv_path) or not os.path.exists(videos_dir):\n",
    "            print(f\"Warning: Processed data not found for '{folder}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        df_labels = pd.read_csv(label_csv_path, sep='\\t')\n",
    "        \n",
    "        for index, row in df_labels.iterrows():\n",
    "            video_name = row['SENTENCE_NAME']\n",
    "            label = row['SENTENCE']\n",
    "            video_filepath = os.path.join(videos_dir, video_name + '.mp4')\n",
    "            \n",
    "            if os.path.exists(video_filepath):\n",
    "                all_video_data.append((video_filepath, label, folder))\n",
    "            else:\n",
    "                print(f\"Missing video file: {video_filepath}. Skipping.\")\n",
    "\n",
    "    if not all_video_data:\n",
    "        print(\"No video data found. Please check your paths and file names.\")\n",
    "        return\n",
    "    print(f\"Total videos found across all sets: {len(all_video_data)}\")\n",
    "\n",
    "    # --- Phase 2: First Pass - Extract & fit scaler on training data ---\n",
    "    print(\"\\n--- Phase 2: Fitting Normalizer on training data ---\")\n",
    "    training_data_raw = []\n",
    "    training_data = [item for item in all_video_data if 'training' in item[2]]\n",
    "\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for video_path, _, _ in tqdm(training_data, desc=\"Extracting Raw Training Keypoints\"):\n",
    "            raw_sequence = process_and_extract_sequence(video_path, holistic)\n",
    "            if raw_sequence is not None and raw_sequence.size > 0:\n",
    "                training_data_raw.append(raw_sequence)\n",
    "\n",
    "    if not training_data_raw:\n",
    "        print(\"No training data found for scaler fitting. Please check your files.\")\n",
    "        return\n",
    "    \n",
    "    combined_train_frames = np.vstack(training_data_raw)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(combined_train_frames)\n",
    "    print(f\"Normalizer (MinMaxScaler) fitted on {combined_train_frames.shape[0]} training frames.\")\n",
    "\n",
    "    # --- Phase 3: Second Pass - Process, Normalize, and Save ---\n",
    "    print(\"\\n--- Phase 3: Normalizing, Padding, and Saving Sequences ---\")\n",
    "    final_data = {'training': {'X': [], 'y': []}, \n",
    "                  'testing': {'X': [], 'y': []}, \n",
    "                  'validation': {'X': [], 'y': []}}\n",
    "    unique_labels = sorted(list(set(item[1] for item in all_video_data)))\n",
    "    label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for video_path, label, folder_type in tqdm(all_video_data, desc=\"Final Processing and Saving\"):\n",
    "            raw_sequence = process_and_extract_sequence(video_path, holistic)\n",
    "            if raw_sequence is None or raw_sequence.size == 0:\n",
    "                continue\n",
    "            padded_sequence = normalize_and_pad_sequence(raw_sequence, scaler)\n",
    "            int_label = label_to_int[label]\n",
    "            key = folder_type.split('_')[1]\n",
    "            final_data[key]['X'].append(padded_sequence)\n",
    "            final_data[key]['y'].append(int_label)\n",
    "    \n",
    "    for set_key, data in final_data.items():\n",
    "        if data['X']:\n",
    "            X_data = np.array(data['X'])\n",
    "            y_data = np.array(data['y'])\n",
    "            np.save(os.path.join(OUTPUT_DATA_DIR, f'X_{set_key}.npy'), X_data)\n",
    "            np.save(os.path.join(OUTPUT_DATA_DIR, f'y_{set_key}.npy'), y_data)\n",
    "            print(f\"\\nSaved {set_key} data: X_shape={X_data.shape}, y_shape={y_data.shape}\")\n",
    "\n",
    "    label_df = pd.DataFrame(list(label_to_int.items()), columns=['SENTENCE', 'LABEL_INT'])\n",
    "    label_df.to_csv(os.path.join(OUTPUT_DATA_DIR, 'label_map.csv'), index=False)\n",
    "    print(f\"\\nLabel map saved with {len(unique_labels)} unique sentences.\")\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data ---\n",
      "X_train shape: (182, 60, 2172)\n",
      "y_train shape: (182,)\n",
      "X_test shape: (84, 60, 2172)\n",
      "y_test shape: (84,)\n",
      "X_val shape: (84, 60, 2172)\n",
      "y_val shape: (84,)\n",
      "Number of classes: 305\n",
      "\n",
      "--- Building and Compiling a Simpler Model ---\n",
      "WARNING:tensorflow:From C:\\Users\\yugos\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yugos\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 60, 32)            211776    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 60, 32)            0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 16)                2400      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                544       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 305)               10065     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 224785 (878.07 KB)\n",
      "Trainable params: 224785 (878.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "--- Starting Model Training ---\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\yugos\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yugos\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "46/46 [==============================] - 23s 214ms/step - loss: 5.7664 - accuracy: 0.0055 - val_loss: 5.7631 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 7s 143ms/step - loss: 5.6717 - accuracy: 0.0000e+00 - val_loss: 5.8772 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 7s 143ms/step - loss: 5.5600 - accuracy: 0.0110 - val_loss: 6.0274 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 5.5147 - accuracy: 0.0000e+00 - val_loss: 6.2850 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 7s 156ms/step - loss: 5.4024 - accuracy: 0.0110 - val_loss: 6.6105 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 5.3508 - accuracy: 0.0055 - val_loss: 6.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 7s 153ms/step - loss: 5.3265 - accuracy: 0.0110 - val_loss: 7.2622 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 7s 148ms/step - loss: 5.3034 - accuracy: 0.0055 - val_loss: 7.5793 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 7s 162ms/step - loss: 5.2978 - accuracy: 0.0000e+00 - val_loss: 7.7287 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 7s 154ms/step - loss: 5.2380 - accuracy: 0.0055 - val_loss: 7.8320 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 5.2392 - accuracy: 0.0110 - val_loss: 8.0357 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 7s 151ms/step - loss: 5.2384 - accuracy: 0.0055 - val_loss: 8.2302 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 6s 133ms/step - loss: 5.2682 - accuracy: 0.0000e+00 - val_loss: 8.3530 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 7s 144ms/step - loss: 5.1803 - accuracy: 0.0055 - val_loss: 8.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 7s 154ms/step - loss: 5.1633 - accuracy: 0.0110 - val_loss: 8.6135 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 7s 162ms/step - loss: 5.1608 - accuracy: 0.0110 - val_loss: 8.8236 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Model training complete.\n",
      "\n",
      "--- Final Model Evaluation on Test Data ---\n",
      "\n",
      "Model Accuracy on Test Data: 0.00%\n",
      "Model Loss on Test Data: 5.8111\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "OUTPUT_DATA_DIR = 'processed_gru_data'\n",
    "\n",
    "# --- 2. DATA LOADING & PREPARATION ---\n",
    "print(\"--- Loading Data ---\")\n",
    "\n",
    "X_train = np.load(os.path.join(OUTPUT_DATA_DIR, 'X_training.npy'))\n",
    "y_train = np.load(os.path.join(OUTPUT_DATA_DIR, 'y_training.npy'))\n",
    "X_test = np.load(os.path.join(OUTPUT_DATA_DIR, 'X_testing.npy'))\n",
    "y_test = np.load(os.path.join(OUTPUT_DATA_DIR, 'y_testing.npy'))\n",
    "X_val = np.load(os.path.join(OUTPUT_DATA_DIR, 'X_validation.npy'))\n",
    "y_val = np.load(os.path.join(OUTPUT_DATA_DIR, 'y_validation.npy'))\n",
    "\n",
    "label_map_df = pd.read_csv(os.path.join(OUTPUT_DATA_DIR, 'label_map.csv'))\n",
    "num_classes = len(label_map_df)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes)\n",
    "y_val_one_hot = to_categorical(y_val, num_classes)\n",
    "\n",
    "# --- 3. BUILD AND COMPILE A SIMPLER GRU MODEL ---\n",
    "print(\"\\n--- Building and Compiling a Simpler Model ---\")\n",
    "\n",
    "num_features = X_train.shape[2]\n",
    "sequence_length = X_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(sequence_length, num_features))) \n",
    "model.add(GRU(32, return_sequences=True))  # Further reduced units\n",
    "model.add(Dropout(0.7))                     # Increased dropout\n",
    "model.add(GRU(16))                        # Reduced units\n",
    "model.add(Dropout(0.7))                     # Increased dropout\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# --- 4. TRAIN THE MODEL ---\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "\n",
    "# Add EarlyStopping to monitor validation loss and prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_one_hot,\n",
    "    epochs=100,\n",
    "    batch_size=4,\n",
    "    validation_data=(X_val, y_val_one_hot),\n",
    "    callbacks=[early_stopping] # Add the callback here\n",
    ")\n",
    "\n",
    "print(\"\\nModel training complete.\")\n",
    "\n",
    "# --- 5. EVALUATE THE MODEL ---\n",
    "print(\"\\n--- Final Model Evaluation on Test Data ---\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "\n",
    "print(f\"\\nModel Accuracy on Test Data: {accuracy * 100:.2f}%\")\n",
    "print(f\"Model Loss on Test Data: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Preprocessing and Aligning Raw Data ---\n",
      "Aligning and processing 'training'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:   2%|█                                                  | 4/182 [00:00<00:04, 39.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_0-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_1-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_10-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_11-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_12-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_13-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_14-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_15-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_16-8-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:   8%|███▊                                              | 14/182 [00:00<00:04, 39.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_17-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_2-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_3-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_4-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_5-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_6-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_7-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_8-8-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  13%|██████▎                                           | 23/182 [00:00<00:04, 38.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized_-_3bUhnn4PU_9-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_0-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_10-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_11-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_12-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_13-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_14-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_15-1-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  18%|████████▊                                         | 32/182 [00:00<00:03, 38.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_16-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_17-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_18-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_19-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_2-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_20-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_21-1-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  20%|██████████▏                                       | 37/182 [00:00<00:03, 39.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_22-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_23-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_24-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_3-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_4-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_5-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_6-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_7-1-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  25%|████████████▎                                     | 45/182 [00:01<00:03, 38.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_8-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized_-_6Fmz29bhU_9-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__-adcxjm1R4_0-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__-adcxjm1R4_1-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0-JkwZ9o4Q_10-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0-JkwZ9o4Q_11-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0-JkwZ9o4Q_12-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0-JkwZ9o4Q_5-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  29%|██████████████▌                                   | 53/182 [00:01<00:03, 37.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__0-JkwZ9o4Q_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0-JkwZ9o4Q_7-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0-JkwZ9o4Q_8-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0-JkwZ9o4Q_9-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0fO5ETSwyg_0-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0fO5ETSwyg_1-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0fO5ETSwyg_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__0fO5ETSwyg_3-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  34%|█████████████████                                 | 62/182 [00:01<00:03, 38.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__15CDIexNDM_0-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__15CDIexNDM_10-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__15CDIexNDM_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__15CDIexNDM_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__15CDIexNDM_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__15CDIexNDM_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__15CDIexNDM_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__15CDIexNDM_7-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  39%|███████████████████▌                              | 71/182 [00:01<00:02, 38.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__15CDIexNDM_8-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__15CDIexNDM_9-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_0-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_1-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_10-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_11-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_12-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_13-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_14-8-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  44%|█████████████████████▉                            | 80/182 [00:02<00:02, 39.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_15-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_16-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_17-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_18-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_19-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_2-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_20-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_21-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_22-8-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  49%|████████████████████████▍                         | 89/182 [00:02<00:02, 40.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_23-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_24-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_3-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_4-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_5-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_6-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_7-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_8-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__20g7MG8K1U_9-8-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  52%|█████████████████████████▊                        | 94/182 [00:02<00:02, 39.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__2u0MkRqpjA_0-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__2u0MkRqpjA_1-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__2u0MkRqpjA_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__2u0MkRqpjA_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__2u0MkRqpjA_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__2u0MkRqpjA_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__2u0MkRqpjA_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__2u0MkRqpjA_7-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  57%|████████████████████████████                     | 104/182 [00:02<00:01, 39.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__45aUonD_So_0-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__4PBd_wiX_A_0-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__4PBd_wiX_A_1-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__4PBd_wiX_A_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__4PBd_wiX_A_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__4PBd_wiX_A_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_0-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_1-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  62%|██████████████████████████████▍                  | 113/182 [00:02<00:01, 39.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_10-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_7-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_8-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5LwGjy_bY8_9-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  68%|█████████████████████████████████                | 123/182 [00:03<00:01, 38.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__5keJZsmTh0_0-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5keJZsmTh0_1-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5keJZsmTh0_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__5keJZsmTh0_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_1-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_10-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_11-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  70%|██████████████████████████████████▏              | 127/182 [00:03<00:01, 37.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_12-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_7-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_8-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__93xgBE3NgA_9-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  75%|████████████████████████████████████▉            | 137/182 [00:03<00:01, 38.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_12-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_13-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_14-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_15-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_16-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_17-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_18-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_19-8-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  80%|███████████████████████████████████████          | 145/182 [00:03<00:00, 37.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_20-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_21-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__BOJ9cYPRe4_22-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_10-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_11-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_12-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_13-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_14-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  84%|█████████████████████████████████████████▏       | 153/182 [00:03<00:00, 37.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_15-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_16-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_17-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_18-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_19-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_20-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_21-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_22-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_23-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  89%|███████████████████████████████████████████▌     | 162/182 [00:04<00:00, 39.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_24-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_25-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_26-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ClrZy5Kkkk_27-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__Dh512GX6d8_0-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__Dh512GX6d8_1-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__Dh512GX6d8_2-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__Dh512GX6d8_3-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__Dh512GX6d8_4-8-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos:  94%|██████████████████████████████████████████████   | 171/182 [00:04<00:00, 40.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_0-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_1-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_10-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_11-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_12-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_2-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_3-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_4-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_5-8-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing training videos: 100%|█████████████████████████████████████████████████| 182/182 [00:04<00:00, 38.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_6-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_7-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_8-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__ci1ieBsGVw_9-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__dEzY_nBD4g_0-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__dEzY_nBD4g_1-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_training\\videos\\standardized__dEzY_nBD4g_2-8-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved processed CSV for training with 182 aligned rows.\n",
      "Aligning and processing 'testing'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:   5%|██▌                                                  | 4/84 [00:00<00:02, 36.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized_3ddzkmFPEBU_0-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__FzvMVnR_aU_1-10-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__FzvMVnR_aU_1-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__FzvMVnR_aU_2-10-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__FzvMVnR_aU_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__FzvMVnR_aU_3-10-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__FzvMVnR_aU_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_0_1_2-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:  15%|████████                                            | 13/84 [00:00<00:01, 41.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_10-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_11-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_12-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_13-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_14-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_15-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_16-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_17-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_3-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:  27%|██████████████▏                                     | 23/84 [00:00<00:01, 40.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_7-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_8-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0MZFLIHa0_9-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_0-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_1-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_10-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:  33%|█████████████████▎                                  | 28/84 [00:00<00:01, 41.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_11-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_12-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_13-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_14-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_15-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_16-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:  39%|████████████████████▍                               | 33/84 [00:00<00:01, 40.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_17-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:  45%|███████████████████████▌                            | 38/84 [00:00<00:01, 41.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_7-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_8-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__G0RrDVpOZ4_9-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_0-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:  57%|█████████████████████████████▋                      | 48/84 [00:01<00:00, 39.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_1-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_10-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_11-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_12-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_13-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_14-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_15-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_16-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:  63%|████████████████████████████████▊                   | 53/84 [00:01<00:00, 39.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_17-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_18-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_19-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_20-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_21-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_22-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:  73%|█████████████████████████████████████▊              | 61/84 [00:01<00:00, 38.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_23-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_24-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_25-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_26-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_6-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:  82%|██████████████████████████████████████████▋         | 69/84 [00:01<00:00, 38.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_7-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_8-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__fZbAxSSbX4_9-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_0-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_0-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_1-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_1-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_2-8-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos:  93%|████████████████████████████████████████████████▎   | 78/84 [00:01<00:00, 39.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_3-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_4-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_5-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_6-8-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_7-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing testing videos: 100%|████████████████████████████████████████████████████| 84/84 [00:02<00:00, 39.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_testing\\videos\\standardized__g0fpC8aiME_7-8-rgb_front.mp4 already exists.\n",
      " Saved processed CSV for testing with 84 aligned rows.\n",
      "Aligning and processing 'validation'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:   0%|                                                          | 0/84 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized_00dWJ4YRRSI_0_1-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_00dWJ4YRRSI_2-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_00dWJ4YRRSI_3-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_00dWJ4YRRSI_4-1-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:   5%|██▍                                               | 4/84 [00:00<00:02, 37.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized_00dWJ4YRRSI_5-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_00dWJ4YRRSI_6-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_00dWJ4YRRSI_7-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_00dWJ4YRRSI_8-1-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  10%|████▊                                             | 8/84 [00:00<00:01, 38.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized_00dWJ4YRRSI_9-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_0-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_1-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_10-1-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  14%|███████                                          | 12/84 [00:00<00:01, 38.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_11-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_12-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_2-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_3-1-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  20%|█████████▉                                       | 17/84 [00:00<00:01, 40.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_4-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_5-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_6-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_7-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_8-1-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  26%|████████████▊                                    | 22/84 [00:00<00:01, 40.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized_0oGfy530AuI_9-1-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_1-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_1-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_10-3-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  32%|███████████████▊                                 | 27/84 [00:00<00:01, 40.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_10-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_11-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_11-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_12-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_12-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  38%|██████████████████▋                              | 32/84 [00:00<00:01, 40.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_2-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_3-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_3-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  44%|█████████████████████▌                           | 37/84 [00:00<00:01, 39.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_4-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_5-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_6-3-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  49%|███████████████████████▉                         | 41/84 [00:01<00:01, 38.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_7-3-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  55%|██████████████████████████▊                      | 46/84 [00:01<00:00, 39.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_7-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_8-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_8-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_9-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__2FBDaOPYig_9-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_2-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_3-3-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  64%|███████████████████████████████▌                 | 54/84 [00:01<00:00, 38.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_3-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_4-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_5-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_6-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_7-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_7-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  76%|█████████████████████████████████████▎           | 64/84 [00:01<00:00, 40.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_8-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_8-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_9-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__5CV2fIG7qY_9-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__64bCfimlk8_6-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__64bCfimlk8_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_1-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_1-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  82%|████████████████████████████████████████▎        | 69/84 [00:01<00:00, 39.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_10-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_10-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_2-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_2-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_3-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_3-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  87%|██████████████████████████████████████████▌      | 73/84 [00:01<00:00, 39.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_4-3-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos:  93%|█████████████████████████████████████████████▌   | 78/84 [00:01<00:00, 39.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_4-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_5-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_5-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_6-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_6-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_7-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_7-5-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_8-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_8-5-rgb_front.mp4 already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Standardizing validation videos: 100%|█████████████████████████████████████████████████| 84/84 [00:02<00:00, 39.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_9-3-rgb_front.mp4 already exists.\n",
      "[SKIP] data\\processed_validation\\videos\\standardized__7uBzSGPQis_9-5-rgb_front.mp4 already exists.\n",
      " Saved processed CSV for validation with 84 aligned rows.\n",
      "\n",
      " All preprocessing and alignment complete.\n",
      "Total videos found after preprocessing: 350\n",
      "Saved video metadata list as 'all_video_data.pkl' for next phase.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import ffmpeg\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "data_root_dir = \"data\"\n",
    "standard_fps = 30\n",
    "standard_resolution = \"640:480\"\n",
    "csv_files_info = {\n",
    "    \"training\": \"how2sign_realigned_train.csv\",\n",
    "    \"testing\": \"how2sign_realigned_test.csv\",\n",
    "    \"validation\": \"how2sign_realigned_val.csv\"\n",
    "}\n",
    "raw_videos_subfolder = \"raw_videos\"\n",
    "\n",
    "# --- HELPER FUNCTION ---\n",
    "def verify_video_properties(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "    return fps, (width, height)\n",
    "\n",
    "\n",
    "# --- PHASE 1: PREPROCESSING & ALIGNMENT ---\n",
    "print(\"--- Phase 1: Preprocessing and Aligning Raw Data ---\")\n",
    "\n",
    "all_video_data_from_processed_dirs = []\n",
    "\n",
    "for folder_name, csv_file_name in csv_files_info.items():\n",
    "    input_videos_dir = os.path.join(data_root_dir, folder_name, raw_videos_subfolder)\n",
    "    input_csv_path = os.path.join(data_root_dir, folder_name, csv_file_name)\n",
    "\n",
    "    processed_videos_dir = os.path.join(data_root_dir, f\"processed_{folder_name}\", \"videos\")\n",
    "    processed_csv_dir = os.path.join(data_root_dir, f\"processed_{folder_name}\")\n",
    "    os.makedirs(processed_videos_dir, exist_ok=True)\n",
    "    os.makedirs(processed_csv_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Aligning and processing '{folder_name}'...\")\n",
    "\n",
    "    if not os.path.exists(input_videos_dir) or not os.path.exists(input_csv_path):\n",
    "        print(f\"Warning: Raw data not found for '{folder_name}'. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    df_raw = pd.read_csv(input_csv_path, sep='\\t')\n",
    "\n",
    "    processed_rows = []\n",
    "    video_id_counter = 0\n",
    "\n",
    "    raw_video_files = [f for f in os.listdir(input_videos_dir) if f.endswith((\".mp4\", \".mov\", \".avi\", \".mkv\"))]\n",
    "    raw_video_names_without_ext = {os.path.splitext(f)[0] for f in raw_video_files}\n",
    "\n",
    "    df_aligned = df_raw[df_raw['SENTENCE_NAME'].isin(raw_video_names_without_ext)].copy()\n",
    "\n",
    "    for index, row in tqdm(df_aligned.iterrows(), total=len(df_aligned), desc=f\"Standardizing {folder_name} videos\"):\n",
    "        video_name = row['SENTENCE_NAME']\n",
    "        label = row['SENTENCE']\n",
    "\n",
    "        video_file_with_ext = next((f for f in raw_video_files if os.path.splitext(f)[0] == video_name), None)\n",
    "        if video_file_with_ext is None:\n",
    "            continue\n",
    "\n",
    "        input_video_path = os.path.join(input_videos_dir, video_file_with_ext)\n",
    "        output_video_path = os.path.join(processed_videos_dir, f\"standardized_{video_name}.mp4\")\n",
    "\n",
    "        # Skip already processed\n",
    "        if os.path.exists(output_video_path):\n",
    "            print(f\"[SKIP] {output_video_path} already exists.\")\n",
    "        else:\n",
    "            try:\n",
    "                (\n",
    "                    ffmpeg\n",
    "                    .input(input_video_path)\n",
    "                    .output(output_video_path, vf=f\"fps={standard_fps},scale={standard_resolution}\",\n",
    "                            vcodec=\"libx264\", crf=20)\n",
    "                    .run(overwrite_output=True, quiet=True)\n",
    "                )\n",
    "            except ffmpeg.Error:\n",
    "                print(f\"Warning: FFmpeg failed for {video_name}.\")\n",
    "                continue\n",
    "\n",
    "        props = verify_video_properties(output_video_path)\n",
    "        if props:\n",
    "            fps, (w, h) = props\n",
    "            if abs(fps - standard_fps) > 1 or (w, h) != tuple(map(int, standard_resolution.split(\":\"))):\n",
    "                print(f\"[WARNING] {video_name}: Non-standard ({fps:.1f} fps, {w}x{h})\")\n",
    "\n",
    "        processed_row = {\n",
    "            'video_id': video_id_counter,\n",
    "            'SENTENCE_NAME': f\"standardized_{video_name}\",\n",
    "            'SENTENCE': label\n",
    "        }\n",
    "        processed_rows.append(processed_row)\n",
    "        video_id_counter += 1\n",
    "\n",
    "    processed_df = pd.DataFrame(processed_rows)\n",
    "    processed_df.to_csv(os.path.join(processed_csv_dir, f\"processed_{folder_name}.csv\"), sep='\\t', index=False)\n",
    "    print(f\" Saved processed CSV for {folder_name} with {len(processed_rows)} aligned rows.\")\n",
    "\n",
    "    for row in processed_rows:\n",
    "        video_path = os.path.join(processed_videos_dir, row['SENTENCE_NAME'] + '.mp4')\n",
    "        all_video_data_from_processed_dirs.append((video_path, row['SENTENCE'], folder_name))\n",
    "\n",
    "print(\"\\n All preprocessing and alignment complete.\")\n",
    "print(f\"Total videos found after preprocessing: {len(all_video_data_from_processed_dirs)}\")\n",
    "\n",
    "# Save video list for next cell\n",
    "import joblib\n",
    "joblib.dump(all_video_data_from_processed_dirs, \"all_video_data.pkl\")\n",
    "print(\"Saved video metadata list as 'all_video_data.pkl' for next phase.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 2: Landmark Extraction & Normalization ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting training landmarks: 100%|███████████████████████████████████████████████| 182/182 [1:24:31<00:00, 27.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scaler fitted and saved with 34215 frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing all videos:  24%|█████████████▌                                          | 85/350 [26:27<2:06:39, 28.68s/it]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import dump, load\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "OUTPUT_DATA_DIR = 'processed_gru_data'\n",
    "SEQUENCE_LENGTH = 60\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# --- LOAD VIDEO LIST ---\n",
    "all_video_data_from_processed_dirs = load(\"all_video_data.pkl\")\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def extract_landmarks(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() \\\n",
    "        if results.pose_landmarks else np.zeros(33 * 4)\n",
    "    face = np.array([[res.x, res.y, res.z, res.visibility] for res in results.face_landmarks.landmark]).flatten() \\\n",
    "        if results.face_landmarks else np.zeros(468 * 4)\n",
    "    lh = np.array([[res.x, res.y, res.z, res.visibility] for res in results.left_hand_landmarks.landmark]).flatten() \\\n",
    "        if results.left_hand_landmarks else np.zeros(21 * 4)\n",
    "    rh = np.array([[res.x, res.y, res.z, res.visibility] for res in results.right_hand_landmarks.landmark]).flatten() \\\n",
    "        if results.right_hand_landmarks else np.zeros(21 * 4)\n",
    "    return np.concatenate([pose, face, lh, rh])\n",
    "\n",
    "\n",
    "def process_and_extract_sequence(video_path, holistic_model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "    frame_sequence = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic_model.process(image_rgb)\n",
    "        keypoints = extract_landmarks(results)\n",
    "        frame_sequence.append(keypoints)\n",
    "    cap.release()\n",
    "    return np.array(frame_sequence) if frame_sequence else None\n",
    "\n",
    "\n",
    "def normalize_and_pad_sequence(sequence, scaler, max_length=SEQUENCE_LENGTH):\n",
    "    if sequence.size == 0:\n",
    "        return np.zeros((max_length, scaler.n_features_in_))\n",
    "    normalized_sequence = scaler.transform(sequence)\n",
    "    if normalized_sequence.shape[0] < max_length:\n",
    "        padding = np.zeros((max_length - normalized_sequence.shape[0], normalized_sequence.shape[1]))\n",
    "        return np.concatenate([normalized_sequence, padding], axis=0)\n",
    "    else:\n",
    "        return normalized_sequence[:max_length, :]\n",
    "\n",
    "\n",
    "# --- PHASE 2: LANDMARK EXTRACTION ---\n",
    "print(\"\\n--- Phase 2: Landmark Extraction & Normalization ---\")\n",
    "\n",
    "training_data = [v for v in all_video_data_from_processed_dirs if v[2] == 'training']\n",
    "final_data = {'training': {'X': [], 'y': []},\n",
    "              'testing': {'X': [], 'y': []},\n",
    "              'validation': {'X': [], 'y': []}}\n",
    "\n",
    "# Extract training data for fitting scaler\n",
    "training_data_raw = []\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    for video_path, _, _ in tqdm(training_data, desc=\"Extracting training landmarks\"):\n",
    "        seq = process_and_extract_sequence(video_path, holistic)\n",
    "        if seq is not None and seq.size > 0:\n",
    "            training_data_raw.append(seq)\n",
    "\n",
    "if not training_data_raw:\n",
    "    raise ValueError(\"No training sequences found. Check your video paths.\")\n",
    "\n",
    "combined_train_frames = np.vstack(training_data_raw)\n",
    "scaler = MinMaxScaler().fit(combined_train_frames)\n",
    "dump(scaler, os.path.join(OUTPUT_DATA_DIR, 'scaler.pkl'))\n",
    "print(f\" Scaler fitted and saved with {combined_train_frames.shape[0]} frames.\")\n",
    "\n",
    "# Build label map\n",
    "unique_labels = sorted(set(label for _, label, _ in all_video_data_from_processed_dirs))\n",
    "label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# --- Normalize, pad, and save all sets ---\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    for video_path, label, folder_type in tqdm(all_video_data_from_processed_dirs, desc=\"Processing all videos\"):\n",
    "        seq = process_and_extract_sequence(video_path, holistic)\n",
    "        if seq is None or seq.size == 0:\n",
    "            continue\n",
    "        seq_norm = normalize_and_pad_sequence(seq, scaler)\n",
    "        final_data[folder_type]['X'].append(seq_norm)\n",
    "        final_data[folder_type]['y'].append(label_to_int[label])\n",
    "\n",
    "for set_key, data in final_data.items():\n",
    "    if data['X']:\n",
    "        X, y = np.array(data['X']), np.array(data['y'])\n",
    "        np.save(os.path.join(OUTPUT_DATA_DIR, f'X_{set_key}.npy'), X)\n",
    "        np.save(os.path.join(OUTPUT_DATA_DIR, f'y_{set_key}.npy'), y)\n",
    "        print(f\" Saved {set_key}: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "pd.DataFrame(label_to_int.items(), columns=['SENTENCE', 'LABEL_INT']).to_csv(\n",
    "    os.path.join(OUTPUT_DATA_DIR, 'label_map.csv'), index=False\n",
    ")\n",
    "print(\"\\n Landmark extraction, normalization, and saving complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
