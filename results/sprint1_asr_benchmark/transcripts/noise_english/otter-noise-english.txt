Hey Adam, let's quickly finalize what will do in sprint one. Sure, so our goal is to bench work existing transcription tools like whisper, Google speech to text and Otter.ai. Right? We need to collect a few short meeting recordings English, Arabic and a mixed one with some code switching. Exactly, then we will run each OT file through those systems and compare the transcripts for metrics we will focus on world error rate and also check how each one handles the noise and speaker separation. Yes, especially in noisy or mixed languages recordings that's where whisper usually does better. I will handle testing on Google speech to text and otter can you run whisper locally. Sure thing, I already set up the model on my machine. Nice. Then, we will prepare a short report like, two or three pages, summarizing the results and limitations. Perfect, let's aim to finish this by the weekend so we can move to sign language handling. Next print, start by gathering the test all used today. Thank you. Yeah.