Hey, Adam, let's quickly finalize what will do in sprint, one. Sure, so our goal is to bench work existing transcription tools like whisper, Google, speech to text and Otter.ai. Right, we need to collect a few short meeting recordings English, Arabic and a mixed one with some code switching. Exactly. Then we will run each OT file through those systems and compare the transcripts. For metrics. We will focus on world error rate and also check how each one handles the noise and speaker separation. Yes, especially in noisy or mixed languages recordings that's where Wes per usually does better. I will handle this thing on Google speech to text and otter can you run with pro locally. Sure thing, I already set up the model in my machine. Nice. Then, we will prepare a short report, like two or three pages, summarizeing the results and limitations. Perfect, let's aim to finish this by the weekend so we can move to sign language handling. Next print. Deal, I'm start by gathering the test audios today. Thank you, yet.  